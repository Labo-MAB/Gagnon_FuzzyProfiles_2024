{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creating more custom plots, figures, and graphs.**\n",
    "\n",
    "The current notebook will generate some figures found in Gagnon at al. 2024. Most of them have been created to highlight some specific results that were not already generated during the actual analysis. *Please note, this notebook doesn't perform any analysis, it simply reuse previously computed results and visualize them.*\n",
    "\n",
    "**Here is a list of the custom figures that will created with the following cells:**\n",
    "\n",
    "1. Radar plot showing mean cognitive and behavioral values and stds for all studies combined. Also generate a radar plot for each individual study.\n",
    "1. Graph network with data coming from the BANDA and GESTE studies labelled. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import get_cmap\n",
    "from matplotlib.colors import rgb2hex\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import f_oneway\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "from neurostatx.network.utils import fetch_attributes_df, fetch_edge_data\n",
    "from neurostatx.network.viz import visualize_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up relevant paths.\n",
    "repository_path = \"/Users/anthonygagnon/code/Article-s-Code/\" # CHANGE THIS\n",
    "abcd_base_path = \"/Volumes/T7/CCPM/ABCD/Release_5.1/abcd-data-release-5.1/\" # CHANGE THIS\n",
    "geste_base_dir = \"/Volumes/T7/CCPM/GESTE/\" # CHANGE THIS\n",
    "banda_dir = '/Volumes/T7/CCPM/BANDA/BANDARelease1.1/' # CHANGE THIS\n",
    "output_folder = \"/Volumes/T7/CCPM/RESULTS_JUNE_24/\" # CHANGE THIS\n",
    "data_dir = f\"{output_folder}/fuzzyclustering/\"\n",
    "output_dir = f\"{output_folder}/viz/\"\n",
    "\n",
    "# Create output directory if it does not exist.\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up the graph network file.\n",
    "G = nx.read_gml(f\"{data_dir}/GraphNetwork.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the attributes from the graph network.\n",
    "attributes_df = fetch_attributes_df(G, attributes='')\n",
    "\n",
    "# Fetch the edge data. \n",
    "edge_df = fetch_edge_data(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generate a radar plot for the global population (all 3 studies).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_plot(X, labels, output, frame='circle', title=\"Radar plot\",\n",
    "               cmap='magma'):\n",
    "    \"\"\"\n",
    "    Function to plot a radar plot for all features in the original dataset\n",
    "    stratified by clusters. T-test between clusters' mean within a feature is\n",
    "    also computed and annotated directly on the plot. When plotting a high\n",
    "    number of clusters, plotting of significant annotation is polluting the\n",
    "    plot, will be fixed in the future.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : DataFrame\n",
    "        Input dataset of shape (S, F).\n",
    "    labels : np.array\n",
    "        Array of hard membership value (S, ).\n",
    "    output : str\n",
    "        Filename of the png file.\n",
    "    frame : str, optional\n",
    "        Shape of the radar plot. Defaults to 'circle'. Choices are 'circle'\n",
    "        or 'polygon'.\n",
    "    title : str, optional\n",
    "        Title of the plot. Defaults to 'Radar plot'.\n",
    "    cmap : str, optional\n",
    "        Colormap to use for the plot. Defaults to 'magma'. See\n",
    "        https://matplotlib.org/stable/tutorials/colors/colormaps.html\n",
    "    \"\"\"\n",
    "\n",
    "    # Setting color palette.\n",
    "    cmap = get_cmap(cmap, len(np.unique(labels)))\n",
    "    colors = [rgb2hex(cmap(i)) for i in range(cmap.N)]\n",
    "\n",
    "    # Make labels start at 1 rather than 0, better for viz.\n",
    "    labels = labels + 1\n",
    "\n",
    "    # Axis labels.\n",
    "    var_labels = X.columns.tolist()\n",
    "    var_labels.append(var_labels[0])\n",
    "\n",
    "    # Computing ANOVA for each features.\n",
    "    anova = []\n",
    "    i = 0\n",
    "    for col in X.columns:\n",
    "        f, p = f_oneway(*[X.loc[labels == k, col] for k in np.unique(labels)])\n",
    "        anova.append(p)\n",
    "        i += 1\n",
    "\n",
    "    # Computing mean values for each features for each clusters.\n",
    "    mean_df = pd.DataFrame()\n",
    "    i = 0\n",
    "    for col in X.columns:\n",
    "        mean = list()\n",
    "        for k in np.unique(labels):\n",
    "            mean.append(X.loc[labels == k, col].mean())\n",
    "        mean_df.insert(i, col, mean)\n",
    "        i += 1\n",
    "\n",
    "    # Computing stds for each features for each clusters.\n",
    "    std_df = pd.DataFrame()\n",
    "    i = 0\n",
    "    for col in X.columns:\n",
    "        std = list()\n",
    "        for k in np.unique(labels):\n",
    "            std.append(X.loc[labels == k, col].std())\n",
    "        std_df.insert(i, col, std)\n",
    "        i += 1\n",
    "    max_val = math.ceil((mean_df + std_df).max().max())\n",
    "    min_val = math.floor((mean_df - std_df).min().min())\n",
    "\n",
    "    mean_df.insert(i, \"Clusters\", np.unique(labels))\n",
    "    std_df.insert(i, \"Clusters\", np.unique(labels))\n",
    "\n",
    "    with plt.rc_context(\n",
    "        {\"font.size\": 12, \"font.weight\": \"bold\", \"axes.titleweight\": \"bold\",\n",
    "         \"font.family\": \"Sans Serif\"}\n",
    "    ):\n",
    "        fig = plt.figure(figsize=(12, 12))\n",
    "        ax = fig.add_subplot(111, polar=True)\n",
    "\n",
    "        # Set radar plot parameters.\n",
    "        theta = create_radar_plot(len(X.columns), frame=frame)\n",
    "\n",
    "        for idx, cluster in enumerate(np.unique(labels)):\n",
    "            values = mean_df.iloc[idx].drop('Clusters').values.tolist()\n",
    "            values.append(values[0])\n",
    "            stds = std_df.iloc[idx].drop('Clusters').values.tolist()\n",
    "            stds.append(stds[0])\n",
    "            stds_pos = [np.sum(x) for x in zip(values, stds)]\n",
    "            stds_neg = [s - d for s, d in zip(values, stds)]\n",
    "            ax.plot(theta, values, c=colors[idx], linewidth=2,\n",
    "                    label=f'Cluster {cluster}', markersize=4, zorder=3)\n",
    "            plot = ax.errorbar(theta, values, yerr=stds, fmt='o-',\n",
    "                               color=colors[idx], linewidth=0,\n",
    "                               label=f'Cluster {cluster}')\n",
    "            ax.fill_between(theta, values, stds_pos, alpha=0.2,\n",
    "                            color=colors[idx], edgecolor='none',\n",
    "                            label='_nolegend_')\n",
    "            ax.fill_between(theta, values, stds_neg, alpha=0.2,\n",
    "                            color=colors[idx], edgecolor='none',\n",
    "                            label='_nolegend_')\n",
    "\n",
    "            plot[-1][0].set_color(colors[idx])\n",
    "\n",
    "    # Add p-values to the plot.\n",
    "    for i, p in enumerate(anova):\n",
    "        if 0.01 < p < 0.05:\n",
    "            ax.text(theta[i], max_val * 0.95, '*', fontsize=24, color='black',\n",
    "                    weight='bold', rotation=math.degrees(theta[i]) + 90)\n",
    "        elif 0.001 < p < 0.01:\n",
    "            ax.text(theta[i], max_val * 0.95, '**', fontsize=24, color='black',\n",
    "                    weight='bold', rotation=math.degrees(theta[i]) + 90)\n",
    "        elif p < 0.001:\n",
    "            ax.text(theta[i], max_val * 0.95, '***', fontsize=24,\n",
    "                    color='black', weight='bold',\n",
    "                    rotation=math.degrees(theta[i]) + 90,\n",
    "                    ha='center', va='center')\n",
    "\n",
    "    # Set legend and variables parameters.\n",
    "    legend = ax.legend(np.unique(labels), loc=(0.95, 0.05), title='Profile #',\n",
    "                       fontsize=14)\n",
    "    frame = legend.get_frame()\n",
    "    frame.set_facecolor('white')\n",
    "    frame.set_edgecolor('black')\n",
    "    ax.set_thetagrids(theta * 180 / np.pi, var_labels, zorder=1)\n",
    "    ax.set_rlabel_position(-36)\n",
    "    ax.set_ylim(min_val, max_val)\n",
    "    yticks = np.arange(min_val, max_val, 0.5)\n",
    "    ax.set_yticks(yticks)\n",
    "\n",
    "    # Set spines and title parameters.\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color('black')\n",
    "        spine.set_linewidth(2)\n",
    "    ax.grid(axis='y', color='lightgray', linewidth=1, zorder=3)\n",
    "    ax.grid(axis='x', color='lightgray', linewidth=.5, zorder=2)\n",
    "    ax.set_facecolor('white')\n",
    "    ax.set_xticklabels(var_labels, fontsize=24, weight='bold')\n",
    "\n",
    "    ax.set_title(f\"{title}\", weight='bold', size=24,\n",
    "                 horizontalalignment='center')\n",
    "\n",
    "    # Set the position for the labels.\n",
    "    for label, angle in zip(ax.get_xticklabels(), theta):\n",
    "        if angle == 0:\n",
    "            label.set_horizontalalignment('left')\n",
    "        elif angle == np.pi:\n",
    "            label.set_horizontalalignment('right')\n",
    "        elif 0 < angle < np.pi / 2 or angle > 3 * np.pi / 2:\n",
    "            label.set_horizontalalignment('left')\n",
    "        else:\n",
    "            label.set_horizontalalignment('right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{output}\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def create_radar_plot(nb_vars, frame='circle'):\n",
    "    \"\"\"\n",
    "    Create a radar chart with `nb_vars` axes.\n",
    "\n",
    "    Args:\n",
    "        nb_vars (int):          Number of variables to plot.\n",
    "        frame (str, optional):  Shape of the radar plot. Defaults to 'circle'.\n",
    "                                Choices are 'circle' or 'polygon'.\n",
    "\n",
    "    Returns:\n",
    "        np.array:               Array of evenly spaced axis angles.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute evenly spaced axis angles.\n",
    "    theta = np.linspace(0, 2 * np.pi, nb_vars, endpoint=False)\n",
    "    theta = np.concatenate((theta, [theta[0]]))\n",
    "\n",
    "    class RadarTransform(PolarAxes.PolarTransform):\n",
    "\n",
    "        def transform_path_non_affine(self, path):\n",
    "            if path._interpolation_steps > 1:\n",
    "                path = path.interpolated(nb_vars)\n",
    "            return Path(self.transform(path.vertices), path.codes)\n",
    "\n",
    "    class RadarAxes(PolarAxes):\n",
    "\n",
    "        name = 'radar'\n",
    "        PolarTransform = RadarTransform\n",
    "\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            # Rotate plot to place the first axis at the top.\n",
    "            self.set_theta_zero_location('N')\n",
    "\n",
    "        def fill(self, *args, closed=True, **kwargs):\n",
    "            \"\"\"Override fill so that line is closed by default.\n",
    "\n",
    "            Args:\n",
    "                closed (bool, optional): _description_. Defaults to True.\n",
    "            \"\"\"\n",
    "            return super().fill(closed=closed, *args, **kwargs)\n",
    "\n",
    "        def plot(self, *args, **kwargs):\n",
    "            \"\"\"\n",
    "            Override plot so that line is closed by default.\n",
    "            \"\"\"\n",
    "            lines = super().plot(*args, **kwargs)\n",
    "            for line in lines:\n",
    "                self._close_line(line)\n",
    "\n",
    "        def _close_line(self, line):\n",
    "            x, y = line.get_data()\n",
    "            if x[0] != x[-1]:\n",
    "                x = np.append(x, x[0])\n",
    "                y = np.append(y, y[0])\n",
    "                line.set_data(x, y)\n",
    "\n",
    "        def set_varlabels(self, labels):\n",
    "            self.set_thetagrids(np.degrees(theta), labels)\n",
    "\n",
    "        def _gen_axes_patch(self):\n",
    "            if frame == 'circle':\n",
    "                return Circle((0.5, 0.5), 0.5)\n",
    "            elif frame == 'polygon':\n",
    "                return RegularPolygon((0.5, 0.5), nb_vars,\n",
    "                                      radius=0.5, edgecolor='k')\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "        def _gen_axes_spines(self):\n",
    "            if frame == 'circle':\n",
    "                return super()._gen_axes_spines()\n",
    "            elif frame == 'polygon':\n",
    "\n",
    "                spine = Spine(axes=self,\n",
    "                              spine_type='circle',\n",
    "                              path=Path.unit_regular_polygon(nb_vars))\n",
    "                spine.set_transform(\n",
    "                    Affine2D().scale(0.5).translate(0.5, 0.5) + self.transAxes)\n",
    "                return {'polar': spine}\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "    register_projection(RadarAxes)\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assertion that index from the attributes df is the same as the edge df.\n",
    "assert np.all(attributes_df.index == edge_df.index), \"Mismatch in index between attributes and edge data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the values by dividing them by the maximum value. Using a loop to avoid hardcoding.\n",
    "vars = ['Internalization', 'Externalization', 'Stress', 'VA', 'EFPS', 'MEM']\n",
    "\n",
    "for var in vars:\n",
    "    attributes_df.loc[:, var] = MinMaxScaler((0, 5)).fit_transform(attributes_df[[var]])\n",
    "\n",
    "membership = np.argmax(edge_df.values, axis=1)\n",
    "attributes_df.loc[:, 'profiles'] = membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_plot(attributes_df.loc[:, vars], attributes_df.profiles, title='Combined',\n",
    "           output=f\"{output_dir}/RadarPlotCombined.png\", cmap=\"bone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating radar plot for each dataset.\n",
    "\n",
    "abcd_df = attributes_df[attributes_df.cohort == 1]\n",
    "banda_df = attributes_df[attributes_df.cohort == 2]\n",
    "geste_df = attributes_df[attributes_df.cohort == 3]\n",
    "\n",
    "radar_plot(abcd_df.loc[:, vars], abcd_df.profiles, title='ABCD Baseline',\n",
    "           output=f\"{output_dir}/RadarPlotABCD.png\", cmap=\"bone\")\n",
    "radar_plot(banda_df.loc[:, vars], banda_df.profiles, title='BANDA',\n",
    "           output=f\"{output_dir}/RadarPlotBANDA.png\", cmap=\"bone\")\n",
    "radar_plot(geste_df.loc[:, vars], geste_df.profiles, title='GESTE',\n",
    "           output=f\"{output_dir}/RadarPlotGESTE.png\", cmap=\"bone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Exporting results from the one-way ANOVA between profiles on the raw cognitive and behavioral variables.**\n",
    "\n",
    "When generating the radar plot, a one-way ANOVA is computed to determine the statistical difference between profiles for each raw variable. However, results are not exported in tabular format but appended to the radar plot. The next cells will compute the ANOVA, and export the results in a table. The exported table will include results from the combined and individual studies. Additionally, Tukey HSD posthoc test will be conducted to further detail the difference in means between each profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the ANOVA for the combined dataset.\n",
    "anova_combined = []\n",
    "for var in vars:\n",
    "    f, p = f_oneway(*[attributes_df.loc[attributes_df.profiles == i, var] for i in np.unique(attributes_df.profiles)])\n",
    "    anova_combined.append([var, f, p])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the ANOVA for each dataset.\n",
    "anova_abcd = []\n",
    "anova_banda = []\n",
    "anova_geste = []\n",
    "\n",
    "for var in vars:\n",
    "    f, p = f_oneway(*[abcd_df.loc[abcd_df.profiles == i, var] for i in np.unique(abcd_df.profiles)])\n",
    "    anova_abcd.append([var, f, p])\n",
    "\n",
    "    f, p = f_oneway(*[banda_df.loc[banda_df.profiles == i, var] for i in np.unique(banda_df.profiles)])\n",
    "    anova_banda.append([var, f, p])\n",
    "\n",
    "    f, p = f_oneway(*[geste_df.loc[geste_df.profiles == i, var] for i in np.unique(geste_df.profiles)])\n",
    "    anova_geste.append([var, f, p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging into a single Pandas DataFrame.\n",
    "anova_combined_df = pd.DataFrame(anova_combined, columns=['Variable', 'F_comb', 'p_comb'])\n",
    "anova_combined_df.set_index('Variable', inplace=True)\n",
    "anova_abcd_df = pd.DataFrame(anova_abcd, columns=['Variable', 'F_abcd', 'p_abcd'])\n",
    "anova_abcd_df.set_index('Variable', inplace=True)\n",
    "anova_banda_df = pd.DataFrame(anova_banda, columns=['Variable', 'F_banda', 'p_banda'])\n",
    "anova_banda_df.set_index('Variable', inplace=True)\n",
    "anova_geste_df = pd.DataFrame(anova_geste, columns=['Variable', 'F_geste', 'p_geste'])\n",
    "anova_geste_df.set_index('Variable', inplace=True)\n",
    "\n",
    "# Merging the DataFrames.\n",
    "anova_df = pd.concat([anova_combined_df, anova_abcd_df, anova_banda_df, anova_geste_df], axis=1)\n",
    "anova_df.to_excel(f\"{output_dir}/ANOVA_results.xlsx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Perform post-hoc Tukey HSD test for pairwise comparison.**\n",
    "\n",
    "The following cells will perform the Tukey HSD post-hoc test to identify pairwise difference between profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add string to profiles label, easy to interpret tables afterwards.\n",
    "attributes_df.loc[:, 'profiles'] = attributes_df.profiles.apply(lambda x: f\"Profile {x+1}\")\n",
    "abcd_df.loc[:, 'profiles'] = abcd_df.profiles.apply(lambda x: f\"Profile {x+1}\")\n",
    "banda_df.loc[:, 'profiles'] = banda_df.profiles.apply(lambda x: f\"Profile {x+1}\")\n",
    "geste_df.loc[:, 'profiles'] = geste_df.profiles.apply(lambda x: f\"Profile {x+1}\")\n",
    "\n",
    "# Tukey's HSD post-hoc test.\n",
    "tukey_combined = []\n",
    "\n",
    "for var in vars:\n",
    "    tukey = pairwise_tukeyhsd(attributes_df[var], attributes_df.profiles, alpha=0.05)\n",
    "    tukey_combined.append(tukey.summary())\n",
    "\n",
    "tukey_abcd = []\n",
    "tukey_banda = []\n",
    "tukey_geste = []\n",
    "\n",
    "for var in vars:\n",
    "    tukey = pairwise_tukeyhsd(abcd_df[var], abcd_df.profiles, alpha=0.05)\n",
    "    tukey_abcd.append(tukey.summary())\n",
    "\n",
    "    tukey = pairwise_tukeyhsd(banda_df[var], banda_df.profiles, alpha=0.05)\n",
    "    tukey_banda.append(tukey.summary())\n",
    "\n",
    "    tukey = pairwise_tukeyhsd(geste_df[var], geste_df.profiles, alpha=0.05)\n",
    "    tukey_geste.append(tukey.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the results to Excel.\n",
    "with pd.ExcelWriter(f\"{output_dir}/Tukey_results.xlsx\") as writer:\n",
    "    for i, var in enumerate(vars):\n",
    "        pd.DataFrame(tukey_combined[i]).to_excel(writer, sheet_name=f\"{var}_combined\", header=False, index=False)\n",
    "        pd.DataFrame(tukey_abcd[i]).to_excel(writer, sheet_name=f\"{var}_abcd\", header=False, index=False)\n",
    "        pd.DataFrame(tukey_banda[i]).to_excel(writer, sheet_name=f\"{var}_banda\", header=False, index=False)\n",
    "        pd.DataFrame(tukey_geste[i]).to_excel(writer, sheet_name=f\"{var}_geste\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Perform an one-way ANOVA to evaluate differences in mean for each profile across studies**\n",
    "\n",
    "The following cells will perform a one-way ANOVA between each cohort for each profile for each variable. Additional post-hoc Tukey HSD will also be performed to pinpoint the differences between cohorts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>Site</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeMonths</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Parent_ed1</th>\n",
       "      <th>Parent_ed2</th>\n",
       "      <th>high_edu</th>\n",
       "      <th>edu_groups</th>\n",
       "      <th>Income</th>\n",
       "      <th>...</th>\n",
       "      <th>PTSD</th>\n",
       "      <th>PSYPATHO</th>\n",
       "      <th>cohort</th>\n",
       "      <th>Internalization</th>\n",
       "      <th>Externalization</th>\n",
       "      <th>Stress</th>\n",
       "      <th>VA</th>\n",
       "      <th>EFPS</th>\n",
       "      <th>MEM</th>\n",
       "      <th>profiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NDAR_INV003RTV85</th>\n",
       "      <td>[-0.03986787796020508, 0.6829884052276611]</td>\n",
       "      <td>site06</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.808537</td>\n",
       "      <td>-0.508119</td>\n",
       "      <td>-0.835551</td>\n",
       "      <td>-0.028635</td>\n",
       "      <td>0.075388</td>\n",
       "      <td>0.075918</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV005V6D2C</th>\n",
       "      <td>[0.6076282262802124, 0.6492170095443726]</td>\n",
       "      <td>site10</td>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.712289</td>\n",
       "      <td>-0.621695</td>\n",
       "      <td>-0.780115</td>\n",
       "      <td>-0.358549</td>\n",
       "      <td>-0.036977</td>\n",
       "      <td>-0.262415</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV007W6H7B</th>\n",
       "      <td>[-0.33013346791267395, -0.009929507039487362]</td>\n",
       "      <td>site22</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.355900</td>\n",
       "      <td>-0.586930</td>\n",
       "      <td>0.172099</td>\n",
       "      <td>0.329778</td>\n",
       "      <td>0.138661</td>\n",
       "      <td>0.444795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV00BD7VDC</th>\n",
       "      <td>[-0.48414772748947144, -0.2177594155073166]</td>\n",
       "      <td>site07</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.034111</td>\n",
       "      <td>-0.323249</td>\n",
       "      <td>0.252535</td>\n",
       "      <td>-0.125655</td>\n",
       "      <td>0.311077</td>\n",
       "      <td>0.495244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NDAR_INV00CY2MDM</th>\n",
       "      <td>[0.2721783518791199, -0.7810755968093872]</td>\n",
       "      <td>site20</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117661</td>\n",
       "      <td>2.090632</td>\n",
       "      <td>1.315690</td>\n",
       "      <td>-0.287412</td>\n",
       "      <td>0.037662</td>\n",
       "      <td>-0.708332</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-2400</th>\n",
       "      <td>[0.49368661642074585, -0.5315656065940857]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39420.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.647188</td>\n",
       "      <td>0.860618</td>\n",
       "      <td>0.701488</td>\n",
       "      <td>-0.555935</td>\n",
       "      <td>-0.350581</td>\n",
       "      <td>-0.362099</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-11441</th>\n",
       "      <td>[-0.8550391793251038, 0.05417872965335846]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>94900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.825163</td>\n",
       "      <td>-0.490999</td>\n",
       "      <td>-0.649811</td>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.171001</td>\n",
       "      <td>0.351421</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-11442</th>\n",
       "      <td>[-0.26875224709510803, -0.48823127150535583]</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>102200.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.536327</td>\n",
       "      <td>-0.490999</td>\n",
       "      <td>0.025487</td>\n",
       "      <td>0.437418</td>\n",
       "      <td>-0.075040</td>\n",
       "      <td>-0.150013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-20161</th>\n",
       "      <td>[0.35089823603630066, -0.5546611547470093]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.072545</td>\n",
       "      <td>0.624448</td>\n",
       "      <td>1.495081</td>\n",
       "      <td>0.230475</td>\n",
       "      <td>0.081190</td>\n",
       "      <td>-0.082217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sub-20162</th>\n",
       "      <td>[0.13311618566513062, -0.9171634316444397]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18250.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.396864</td>\n",
       "      <td>1.633737</td>\n",
       "      <td>0.843684</td>\n",
       "      <td>0.397434</td>\n",
       "      <td>-0.148352</td>\n",
       "      <td>-0.366017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11309 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            pos    Site  Sex  \\\n",
       "NDAR_INV003RTV85     [-0.03986787796020508, 0.6829884052276611]  site06    2   \n",
       "NDAR_INV005V6D2C       [0.6076282262802124, 0.6492170095443726]  site10    2   \n",
       "NDAR_INV007W6H7B  [-0.33013346791267395, -0.009929507039487362]  site22    1   \n",
       "NDAR_INV00BD7VDC    [-0.48414772748947144, -0.2177594155073166]  site07    1   \n",
       "NDAR_INV00CY2MDM      [0.2721783518791199, -0.7810755968093872]  site20    1   \n",
       "...                                                         ...     ...  ...   \n",
       "sub-2400             [0.49368661642074585, -0.5315656065940857]       0    1   \n",
       "sub-11441            [-0.8550391793251038, 0.05417872965335846]       0    2   \n",
       "sub-11442          [-0.26875224709510803, -0.48823127150535583]       0    2   \n",
       "sub-20161            [0.35089823603630066, -0.5546611547470093]       0    1   \n",
       "sub-20162            [0.13311618566513062, -0.9171634316444397]       0    1   \n",
       "\n",
       "                  AgeMonths  Ethnicity  Parent_ed1  Parent_ed2  high_edu  \\\n",
       "NDAR_INV003RTV85        131          1        13.0        13.0      13.0   \n",
       "NDAR_INV005V6D2C        121          3         6.0         0.0       6.0   \n",
       "NDAR_INV007W6H7B        126          1        19.0        18.0      19.0   \n",
       "NDAR_INV00BD7VDC        112          1        20.0        20.0      20.0   \n",
       "NDAR_INV00CY2MDM        130          1        15.0         0.0      15.0   \n",
       "...                     ...        ...         ...         ...       ...   \n",
       "sub-2400                131          1         3.0         5.0       0.0   \n",
       "sub-11441               130          1         4.0         3.0       0.0   \n",
       "sub-11442               130          1         4.0         3.0       0.0   \n",
       "sub-20161               151          1         5.0         1.0       0.0   \n",
       "sub-20162               151          1         5.0         1.0       0.0   \n",
       "\n",
       "                  edu_groups    Income  ...  PTSD  PSYPATHO  cohort  \\\n",
       "NDAR_INV003RTV85         2.0       8.0  ...     0         0       1   \n",
       "NDAR_INV005V6D2C         1.0     999.0  ...     0         0       1   \n",
       "NDAR_INV007W6H7B         5.0      10.0  ...     0         0       1   \n",
       "NDAR_INV00BD7VDC         5.0      10.0  ...     0         1       1   \n",
       "NDAR_INV00CY2MDM         3.0       6.0  ...     0         1       1   \n",
       "...                      ...       ...  ...   ...       ...     ...   \n",
       "sub-2400                 5.0   39420.0  ...     0         1       3   \n",
       "sub-11441                4.0   94900.0  ...     0         0       3   \n",
       "sub-11442                4.0  102200.0  ...     0         0       3   \n",
       "sub-20161                5.0   18250.0  ...     0         0       3   \n",
       "sub-20162                5.0   18250.0  ...     0         1       3   \n",
       "\n",
       "                  Internalization  Externalization    Stress        VA  \\\n",
       "NDAR_INV003RTV85        -0.808537        -0.508119 -0.835551 -0.028635   \n",
       "NDAR_INV005V6D2C        -0.712289        -0.621695 -0.780115 -0.358549   \n",
       "NDAR_INV007W6H7B         0.355900        -0.586930  0.172099  0.329778   \n",
       "NDAR_INV00BD7VDC         0.034111        -0.323249  0.252535 -0.125655   \n",
       "NDAR_INV00CY2MDM         0.117661         2.090632  1.315690 -0.287412   \n",
       "...                           ...              ...       ...       ...   \n",
       "sub-2400                 0.647188         0.860618  0.701488 -0.555935   \n",
       "sub-11441               -0.825163        -0.490999 -0.649811  0.691489   \n",
       "sub-11442                0.536327        -0.490999  0.025487  0.437418   \n",
       "sub-20161                2.072545         0.624448  1.495081  0.230475   \n",
       "sub-20162                0.396864         1.633737  0.843684  0.397434   \n",
       "\n",
       "                      EFPS       MEM  profiles  \n",
       "NDAR_INV003RTV85  0.075388  0.075918         2  \n",
       "NDAR_INV005V6D2C -0.036977 -0.262415         3  \n",
       "NDAR_INV007W6H7B  0.138661  0.444795         0  \n",
       "NDAR_INV00BD7VDC  0.311077  0.495244         2  \n",
       "NDAR_INV00CY2MDM  0.037662 -0.708332         1  \n",
       "...                    ...       ...       ...  \n",
       "sub-2400         -0.350581 -0.362099         1  \n",
       "sub-11441         0.171001  0.351421         2  \n",
       "sub-11442        -0.075040 -0.150013         0  \n",
       "sub-20161         0.081190 -0.082217         0  \n",
       "sub-20162        -0.148352 -0.366017         1  \n",
       "\n",
       "[11309 rows x 29 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch membership values and attribute them to their main profile.\n",
    "membership = np.argmax(edge_df.values, axis=1)\n",
    "attributes_df.loc[:, 'profiles'] = membership\n",
    "\n",
    "# Compute the differences between the profiles between cohorts.\n",
    "c1_df = attributes_df[attributes_df.profiles == 0]\n",
    "c2_df = attributes_df[attributes_df.profiles == 1]\n",
    "c3_df = attributes_df[attributes_df.profiles == 2]\n",
    "c4_df = attributes_df[attributes_df.profiles == 3]\n",
    "\n",
    "# Compute the differences between the profiles between cohorts.\n",
    "anova_c1 = []\n",
    "anova_c2 = []\n",
    "anova_c3 = []\n",
    "anova_c4 = []\n",
    "\n",
    "vars = ['Internalization', 'Externalization', 'Stress', 'VA', 'EFPS', 'MEM']\n",
    "\n",
    "for var in vars:\n",
    "    f, p = f_oneway(*[c1_df.loc[c1_df.cohort == i, var] for i in np.unique(c1_df.cohort)])\n",
    "    anova_c1.append([var, f, p])\n",
    "    f, p = f_oneway(*[c2_df.loc[c2_df.cohort == i, var] for i in np.unique(c2_df.cohort)])\n",
    "    anova_c2.append([var, f, p])\n",
    "    f, p = f_oneway(*[c3_df.loc[c3_df.cohort == i, var] for i in np.unique(c3_df.cohort)])\n",
    "    anova_c3.append([var, f, p])\n",
    "    f, p = f_oneway(*[c4_df.loc[c4_df.cohort == i, var] for i in np.unique(c4_df.cohort)])\n",
    "    anova_c4.append([var, f, p])\n",
    "\n",
    "anova_c1 = pd.DataFrame(anova_c1, columns=['Variable', 'F_c1', 'p_c1'])\n",
    "anova_c1.set_index('Variable', inplace=True)\n",
    "anova_c2 = pd.DataFrame(anova_c2, columns=['Variable', 'F_c2', 'p_c2'])\n",
    "anova_c2.set_index('Variable', inplace=True)\n",
    "anova_c3 = pd.DataFrame(anova_c3, columns=['Variable', 'F_c3', 'p_c3'])\n",
    "anova_c3.set_index('Variable', inplace=True)\n",
    "anova_c4 = pd.DataFrame(anova_c4, columns=['Variable', 'F_c4', 'p_c4'])\n",
    "anova_c4.set_index('Variable', inplace=True)\n",
    "\n",
    "# Concatenate the DataFrames.\n",
    "anova_c = pd.concat([anova_c1, anova_c2, anova_c3, anova_c4], axis=1)\n",
    "anova_c.to_excel(f\"{output_dir}/ANOVA_results_cohorts.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tukey's HSD post-hoc test.\n",
    "tukey_c1 = []\n",
    "tukey_c2 = []\n",
    "tukey_c3 = []\n",
    "tukey_c4 = []\n",
    "\n",
    "for var in vars:\n",
    "    tukey = pairwise_tukeyhsd(c1_df[var], c1_df.cohort, alpha=0.05)\n",
    "    tukey_c1.append(tukey.summary())\n",
    "\n",
    "    tukey = pairwise_tukeyhsd(c2_df[var], c2_df.cohort, alpha=0.05)\n",
    "    tukey_c2.append(tukey.summary())\n",
    "\n",
    "    tukey = pairwise_tukeyhsd(c3_df[var], c3_df.cohort, alpha=0.05)\n",
    "    tukey_c3.append(tukey.summary())\n",
    "\n",
    "    tukey = pairwise_tukeyhsd(c4_df[var], c4_df.cohort, alpha=0.05)\n",
    "    tukey_c4.append(tukey.summary())\n",
    "\n",
    "# Export the results to Excel.\n",
    "with pd.ExcelWriter(f\"{output_dir}/Tukey_results_cohorts.xlsx\") as writer:\n",
    "    for i, var in enumerate(vars):\n",
    "        pd.DataFrame(tukey_c1[i]).to_excel(writer, sheet_name=f\"{var}_c1\", header=False, index=False)\n",
    "        pd.DataFrame(tukey_c2[i]).to_excel(writer, sheet_name=f\"{var}_c2\", header=False, index=False)\n",
    "        pd.DataFrame(tukey_c3[i]).to_excel(writer, sheet_name=f\"{var}_c3\", header=False, index=False)\n",
    "        pd.DataFrame(tukey_c4[i]).to_excel(writer, sheet_name=f\"{var}_c4\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generate a Graph Network file with GESTE and BANDA data labelled.**\n",
    "\n",
    "The next cells will generate a graph network figure highlight subjects coming from the BANDA and GESTE study. The main purpose of this figure is to evaluated the distribution of both studies across the graph network. Since it is projected onto the ABCD clustering results, we want to ensure that it covers the majority of the graph, and not only specific regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate colormap for the different cohorts.\n",
    "label = attributes_df['cohort'].values\n",
    "\n",
    "nodes_cmap = []\n",
    "for i in label:\n",
    "    if i == 1:\n",
    "        nodes_cmap.append(\"darkgrey\")\n",
    "    elif i == 2:\n",
    "        nodes_cmap.append(\"red\")\n",
    "    else:\n",
    "        nodes_cmap.append(\"orange\")\n",
    "\n",
    "# Create node alpha list.\n",
    "nodes_alpha = []\n",
    "for i in nodes_cmap:\n",
    "    if i == \"darkgrey\":\n",
    "        nodes_alpha.append(0.3)\n",
    "    else:\n",
    "        nodes_alpha.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the network.\n",
    "visualize_network(G, output=f'{output_dir}/NetworkCohort.png',\n",
    "                  weight='membership',\n",
    "                  subject_node_color=nodes_cmap,\n",
    "                  subject_alpha=nodes_alpha,\n",
    "                  colormap='bone_r',\n",
    "                  title='Cohort labelling.',\n",
    "                  legend_title='Membership Values')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualize the diagnosis labels from the youth KSADS on the Graph Network.**\n",
    "\n",
    "The next cells will generate a visualization of the graph network while highlighting participants with a diagnosis reported using the KSADS youth instrument. This is particularly interesting to compare with the distribution of diagnoses reported using the KSADS parent instruments, as it has been suggested that results may vary based on the responder (child or parent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the GraphNetwork file from the awp folder.\n",
    "G = nx.read_gml(f\"{output_folder}/awp/GraphNetwork_youth.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch attributes. \n",
    "attr = fetch_attributes_df(G, attributes='')\n",
    "\n",
    "attr['AD_youth'] = attr['AD_youth'].fillna(0)\n",
    "attr['DD_youth'] = attr['DD_youth'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_cmap = []\n",
    "for i in attr['AD_youth'].values:\n",
    "    if i == 1:\n",
    "        nodes_cmap.append(\"orange\")\n",
    "    else:\n",
    "        nodes_cmap.append(\"darkgrey\")\n",
    "\n",
    "# Create node alpha list.\n",
    "nodes_alpha = []\n",
    "for i in nodes_cmap:\n",
    "    if i == \"darkgrey\":\n",
    "        nodes_alpha.append(0.3)\n",
    "    else:\n",
    "        nodes_alpha.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the network.\n",
    "visualize_network(G, output=f'{output_dir}/NetworkABCD_AD_youth.png',\n",
    "                  weight='membership',\n",
    "                  subject_node_color=nodes_cmap,\n",
    "                  subject_alpha=nodes_alpha,\n",
    "                  colormap='bone_r',\n",
    "                  title='ABCD AD Youth',\n",
    "                  legend_title='AD Youth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_cmap = []\n",
    "for i in attr['DD_youth'].values:\n",
    "    if i == 1:\n",
    "        nodes_cmap.append(\"orange\")\n",
    "    else:\n",
    "        nodes_cmap.append(\"darkgrey\")\n",
    "\n",
    "# Create node alpha list.\n",
    "nodes_alpha = []\n",
    "for i in nodes_cmap:\n",
    "    if i == \"darkgrey\":\n",
    "        nodes_alpha.append(0.3)\n",
    "    else:\n",
    "        nodes_alpha.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the network.\n",
    "visualize_network(G, output=f'{output_dir}/NetworkABCD_DD_youth.png',\n",
    "                  weight='membership',\n",
    "                  subject_node_color=nodes_cmap,\n",
    "                  subject_alpha=nodes_alpha,\n",
    "                  colormap='bone_r',\n",
    "                  title='ABCD DD Youth',\n",
    "                  legend_title='DD Youth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PSYPATHO index.\n",
    "attr['PSYPATHO_youth'] = attr['PSYPATHO_youth'].fillna(0)\n",
    "\n",
    "nodes_cmap = []\n",
    "for i in attr['PSYPATHO_youth'].values:\n",
    "    if i == 1:\n",
    "        nodes_cmap.append(\"orange\")\n",
    "    else:\n",
    "        nodes_cmap.append(\"darkgrey\")\n",
    "\n",
    "# Create node alpha list.\n",
    "nodes_alpha = []\n",
    "for i in nodes_cmap:\n",
    "    if i == \"darkgrey\":\n",
    "        nodes_alpha.append(0.3)\n",
    "    else:\n",
    "        nodes_alpha.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the network.\n",
    "visualize_network(G, output=f'{output_dir}/NetworkABCD_PSYPATHO_youth.png',\n",
    "                  weight='membership',\n",
    "                  subject_node_color=nodes_cmap,\n",
    "                  subject_alpha=nodes_alpha,\n",
    "                  colormap='bone_r',\n",
    "                  title='ABCD PSYPATHO Youth',\n",
    "                  legend_title='Membership Values')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neurostatx-0.1.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
