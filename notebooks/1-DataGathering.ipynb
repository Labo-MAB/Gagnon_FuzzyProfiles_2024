{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **IMPORTING RELEVANT DATASET AND FEATURE SELECTION** \n",
    "\n",
    "This section will import all the relevant dataset needed to run the analysis\n",
    "from Gagnon et al., XXXX. Feature selection will be performed to keep only the\n",
    "relevant variables. \n",
    "\n",
    "#### **Setting up relevant paths.**\n",
    "\n",
    "In order for the following analyses to work, please update the following\n",
    "variables in the next cell.\n",
    "\n",
    "1. `repository_path`: should point to the location of the git repository.\n",
    "1. `abcd_base_path`: should point to the base folder of the abcd data release.\n",
    "1. `output_folder`: should point to a folder in which results will be outputted throughout the analyses. \n",
    "\n",
    "#### **Requirements.**\n",
    "\n",
    "To be able to run the following code, it is mandatory to install the NeuroStatX\n",
    "toolbox (https://github.com/gagnonanthony/NeuroStatX.git). If it isn't already\n",
    "install on your machine, please run the above cell (or follow the instructions\n",
    "on the repository/documentation). All the analyses should be\n",
    "runnable on a entry-level computer (time to complete some steps might vary,\n",
    "long running steps are label by **This is a long running process. Go get a\n",
    "coffee !**). You may choose to skip some of these steps if need be.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from neurostatx.io.utils import load_df_in_any_format\n",
    "from neurostatx.utils.preprocessing import merge_dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up relevant paths.\n",
    "repository_path = \"/Users/anthonygagnon/code/Article-s-Code/\" # CHANGE THIS\n",
    "abcd_base_path = \"/Volumes/T7/CCPM/ABCD/Release_5.1/abcd-data-release-5.1/\" # CHANGE THIS\n",
    "geste_base_dir = \"/Volumes/T7/CCPM/GESTE/\" # CHANGE THIS\n",
    "banda_dir = '/Volumes/T7/CCPM/BANDA/BANDARelease1.1/' # CHANGE THIS\n",
    "output_folder = \"/Volumes/T7/CCPM/RESULTS_JUNE_24/\" # CHANGE THIS\n",
    "\n",
    "# Setting up the paths for the data.\n",
    "output_dir = f\"{output_folder}/datagathering/\" # DO NOT CHANGE THIS\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fetching relevant data for the ABCD Study.**\n",
    "\n",
    "Subsequent cells will load table from the ABCD Release 5.1, filter to keep only baseline data, and keep relevant variables for the present analysis. Final table will be outputted in the above specified `output_dir`.\n",
    "\n",
    "**Please note that this dataset is available through a data use certificate. For more informations, please see the [NIMH Data Archive website](https://nda.nih.gov/) or the [ABCD Study wiki](https://wiki.abcdstudy.org/)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anthonygagnon/code/NeuroStatX/neurostatx/io/utils.py:25: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/Users/anthonygagnon/code/NeuroStatX/neurostatx/io/utils.py:25: DtypeWarning: Columns (274) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/Users/anthonygagnon/code/NeuroStatX/neurostatx/io/utils.py:25: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/Users/anthonygagnon/code/NeuroStatX/neurostatx/io/utils.py:25: DtypeWarning: Columns (124,128,132,136,140,144,148,152,156,160,164,168,172,176,180,184,188,192,196,200) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n",
      "/Users/anthonygagnon/code/NeuroStatX/neurostatx/io/utils.py:25: DtypeWarning: Columns (49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file)\n"
     ]
    }
   ],
   "source": [
    "# Load all necessary data tables. \n",
    "lt = load_df_in_any_format(f'{abcd_base_path}/core/abcd-general/abcd_y_lt.csv')\n",
    "lt = lt.loc[lt.eventname == 'baseline_year_1_arm_1']\n",
    "demo = load_df_in_any_format(f'{abcd_base_path}/core/abcd-general/abcd_p_demo.csv')\n",
    "demo = demo.loc[demo.eventname == 'baseline_year_1_arm_1']\n",
    "agemonth = load_df_in_any_format(f'{abcd_base_path}/core/abcd-general/abcd_y_lt.csv')\n",
    "agemonth = agemonth.loc[agemonth.eventname == 'baseline_year_1_arm_1']\n",
    "cbcl = load_df_in_any_format(f'{abcd_base_path}/core/mental-health/mh_p_cbcl.csv')\n",
    "cbcl = cbcl.loc[cbcl.eventname == 'baseline_year_1_arm_1']\n",
    "nihtb = load_df_in_any_format(f'{abcd_base_path}/core/neurocognition/nc_y_nihtb.csv')\n",
    "nihtb = nihtb.loc[nihtb.eventname == 'baseline_year_1_arm_1']\n",
    "lmt = load_df_in_any_format(f'{abcd_base_path}/core/neurocognition/nc_y_lmt.csv')\n",
    "lmt = lmt.loc[lmt.eventname == 'baseline_year_1_arm_1']\n",
    "ravlt = load_df_in_any_format(f'{abcd_base_path}/core/neurocognition/nc_y_ravlt.csv')\n",
    "ravlt = ravlt.loc[ravlt.eventname == 'baseline_year_1_arm_1']\n",
    "wisc = load_df_in_any_format(f'{abcd_base_path}/core/neurocognition/nc_y_wisc.csv')\n",
    "wisc = wisc.loc[wisc.eventname == 'baseline_year_1_arm_1']\n",
    "hand = load_df_in_any_format(f'{abcd_base_path}/core/neurocognition/nc_y_ehis.csv')\n",
    "hand = hand.loc[hand.eventname == 'baseline_year_1_arm_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting syndrome scores.\n",
    "syndromes = [\n",
    "    \"src_subject_id\",\n",
    "    \"cbcl_scr_syn_internal_r\",\n",
    "    \"cbcl_scr_syn_external_r\",\n",
    "    \"cbcl_scr_07_stress_r\"\n",
    "]\n",
    "cbcl_scores = cbcl[syndromes]\n",
    "cbcl_scores.columns = [\n",
    "    \"subjectkey\",\n",
    "    \"Internalization\",\n",
    "    \"Externalization\",\n",
    "    \"Stress\"\n",
    "]\n",
    "cbcl_scores.loc[:, 'Internalization'] = StandardScaler().fit_transform(cbcl_scores[['Internalization']])\n",
    "cbcl_scores.loc[:, 'Externalization'] = StandardScaler().fit_transform(cbcl_scores[['Externalization']])\n",
    "cbcl_scores.loc[:, 'Stress'] = StandardScaler().fit_transform(cbcl_scores[['Stress']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lumping variaable within a common dataframe.\n",
    "# NIH Toolbox\n",
    "nihtb_vars = [\n",
    "    \"src_subject_id\",\n",
    "    \"nihtbx_picvocab_uncorrected\",\n",
    "    \"nihtbx_flanker_uncorrected\",\n",
    "    \"nihtbx_list_uncorrected\",\n",
    "    \"nihtbx_cardsort_uncorrected\",\n",
    "    \"nihtbx_pattern_uncorrected\",\n",
    "    \"nihtbx_picture_uncorrected\",\n",
    "    \"nihtbx_reading_uncorrected\",\n",
    "]\n",
    "nihtb_scores = nihtb[nihtb_vars]\n",
    "nihtb_scores.columns = [\n",
    "    \"subjectkey\",\n",
    "    \"PictureVocab\",\n",
    "    \"Flanker\",\n",
    "    \"ListSorting\",\n",
    "    \"CardSort\",\n",
    "    \"PatternComparison\",\n",
    "    \"PictureSequence\",\n",
    "    \"OralReading\"\n",
    "]\n",
    "nihtb_scores.loc[:, 'PictureVocab'] = StandardScaler().fit_transform(nihtb_scores[['PictureVocab']])\n",
    "nihtb_scores.loc[:, 'Flanker'] = StandardScaler().fit_transform(nihtb_scores[['Flanker']])\n",
    "nihtb_scores.loc[:, 'ListSorting'] = StandardScaler().fit_transform(nihtb_scores[['ListSorting']])\n",
    "nihtb_scores.loc[:, 'CardSort'] = StandardScaler().fit_transform(nihtb_scores[['CardSort']])\n",
    "nihtb_scores.loc[:, 'PatternComparison'] = StandardScaler().fit_transform(nihtb_scores[['PatternComparison']])\n",
    "nihtb_scores.loc[:, 'PictureSequence'] = StandardScaler().fit_transform(nihtb_scores[['PictureSequence']])\n",
    "nihtb_scores.loc[:, 'OralReading'] = StandardScaler().fit_transform(nihtb_scores[['OralReading']])\n",
    "\n",
    "# Little Man's Task.\n",
    "lmt_vars = [\n",
    "    \"src_subject_id\",\n",
    "    \"lmt_scr_perc_correct\"\n",
    "]\n",
    "lmt_scores = lmt[lmt_vars]\n",
    "lmt_scores.columns = [\n",
    "    \"subjectkey\",\n",
    "    \"LMT\"\n",
    "]\n",
    "lmt_scores.loc[:, 'LMT'] = StandardScaler().fit_transform(lmt_scores[['LMT']])\n",
    "\n",
    "# Pearson's RAVLT.\n",
    "ravlt_vars = [\n",
    "    \"src_subject_id\",\n",
    "    \"pea_ravlt_ld_trial_vii_tc\"\n",
    "]\n",
    "ravlt_scores = ravlt[ravlt_vars]\n",
    "ravlt_scores.columns = [\n",
    "    \"subjectkey\",\n",
    "    \"RAVLT\"\n",
    "]\n",
    "ravlt_scores.loc[:, 'RAVLT'] = StandardScaler().fit_transform(ravlt_scores[['RAVLT']])\n",
    "\n",
    "# WISC.\n",
    "wisc_vars = [\n",
    "    \"src_subject_id\",\n",
    "    \"pea_wiscv_tss\"\n",
    "]\n",
    "wisc_scores = wisc[wisc_vars]\n",
    "wisc_scores.columns = [\n",
    "    \"subjectkey\",\n",
    "    \"WISCMatrix\"\n",
    "]\n",
    "wisc_scores.loc[:, 'WISCMatrix'] = StandardScaler().fit_transform(wisc_scores[['WISCMatrix']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the diagnosis labels.\n",
    "!python {repository_path}/scripts/generate_dx_ABCD.py --in-root-folder {abcd_base_path} \\\n",
    "    --output {output_dir}/abcd_dx_labels.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing back the diagnosis labels.\n",
    "dx_labels = load_df_in_any_format(f'{output_dir}/abcd_dx_labels.xlsx')\n",
    "\n",
    "# Add a global psychopathology score (1 = at least one diagnosis, 0 = no diagnosis).\n",
    "dx_labels.loc[:, 'PSYPATHO'] = dx_labels.iloc[:, 1:].sum(axis=1).apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching basic demographics.\n",
    "site_vars = [\n",
    "    \"src_subject_id\",\n",
    "    \"site_id_l\"\n",
    "]\n",
    "site = lt[site_vars]\n",
    "site.columns = [\n",
    "    \"subjectkey\",\n",
    "    \"Site\"\n",
    "]\n",
    "demo_vars = [\n",
    "    \"src_subject_id\",\n",
    "    \"demo_sex_v2\",\n",
    "    \"race_ethnicity\",\n",
    "    \"demo_prnt_ed_v2\",\n",
    "    \"demo_prtnr_ed_v2\",\n",
    "    \"demo_comb_income_v2\",\n",
    "]\n",
    "demo = demo[demo_vars]\n",
    "demo.columns = [\n",
    "    \"subjectkey\",\n",
    "    \"Sex\",\n",
    "    \"Ethnicity\",\n",
    "    \"Parent_ed1\",\n",
    "    \"Parent_ed2\",\n",
    "    \"Income\"\n",
    "]\n",
    "agemonth_vars = [\n",
    "    \"src_subject_id\",\n",
    "    \"interview_age\"\n",
    "]\n",
    "agemonth = agemonth[agemonth_vars]\n",
    "agemonth.columns = [\n",
    "    \"subjectkey\",\n",
    "    \"AgeMonths\"\n",
    "]\n",
    "hand = hand[['src_subject_id', 'ehi_y_ss_scoreb']]\n",
    "hand.columns = ['subjectkey', 'Handedness']\n",
    "\n",
    "# Invert the handedness score to match other dataset. 1 = left, 2 = right, 3 = ambidextrous.\n",
    "def invert_handedness(x):\n",
    "    if x == 1:\n",
    "        return 2\n",
    "    elif x == 2:\n",
    "        return 1\n",
    "    elif x == 3:\n",
    "        return 3\n",
    "    else:\n",
    "        return np.nan\n",
    "hand.loc[:, 'Handedness'] = hand.Handedness.apply(invert_handedness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some demographics variables.\n",
    "# Highest education level (parent). Taking the highest amongst the two parents.\n",
    "demo.loc[:, 'Parent_ed2'] = demo['Parent_ed2'].replace([777, 999, np.nan], 0)\n",
    "demo.loc[:, 'high_edu'] = demo[['Parent_ed1', 'Parent_ed2']].values.max(1)\n",
    "\n",
    "# Group levels together (<13 = 1, no high school, 13-14 = 2, high school, ged or equivalent,\n",
    "# 15-17 = 3, some college, 18 = 4, bachelor, >19 = 5, postgraduate)\n",
    "def create_edu_groups(x):\n",
    "    if x < 13:\n",
    "        return 1\n",
    "    elif x in [13, 14]:\n",
    "        return 2\n",
    "    elif x in [15, 16, 17]:\n",
    "        return 3\n",
    "    elif x == 18:\n",
    "        return 4\n",
    "    elif x in [19, 20, 21]:\n",
    "        return 5\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "demo.loc[:, 'edu_groups'] = demo['high_edu'].apply(create_edu_groups)\n",
    "\n",
    "# Group levels of income together ( <6 = 1, < 50 000, 6-8 = 2, 50-100 000, >9 = 3, >100 000).\n",
    "def create_income_groups(x):\n",
    "    if x < 6:\n",
    "        return 1\n",
    "    elif x in [6, 7, 8]:\n",
    "        return 2\n",
    "    elif x in [9, 10]:\n",
    "        return 3\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "demo.loc[:, 'income_groups'] = demo['Income'].apply(create_income_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects retained for the analysis: 10843\n"
     ]
    }
   ],
   "source": [
    "# First, merging psychometrics and behavioral data, then merging with demographics.\n",
    "# This way, we avoid the loss of subjects due to missing data in demographics columns.\n",
    "psy_behav = merge_dataframes({\"age\": agemonth, \"dx\": dx_labels,\n",
    "                            \"cbcl\": cbcl_scores, \"nihtb\": nihtb_scores,\n",
    "                            \"lmt\": lmt_scores, \"ravlt\": ravlt_scores,\n",
    "                            \"wisc\": wisc_scores}, index=\"subjectkey\")\n",
    "psy_behav.dropna(inplace=True, axis=0)\n",
    "psy_behav.reset_index(drop=False, inplace=True)\n",
    "print(\"Number of subjects retained for the analysis: {}\".format(psy_behav.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating all the dataframes.\n",
    "abcd_data = merge_dataframes({\"site\": site, \"demo\": demo, \"hand\": hand,\n",
    "                                \"psy_behav\": psy_behav}, index=\"subjectkey\")\n",
    "# Dropping rows with NA in the last 6 columns which corresponds to the behavioral and psychometric data.\n",
    "abcd_data.dropna(inplace=True, axis=0, subset=abcd_data.columns[-6:], how=\"all\")\n",
    "\n",
    "# Reordering the columns.\n",
    "abcd_data = abcd_data[[\"Site\", \"Sex\", \"AgeMonths\", \"Ethnicity\", \"Parent_ed1\",\n",
    "                       \"Parent_ed2\", \"high_edu\", \"edu_groups\", \"Income\", \"income_groups\",\n",
    "                       \"Handedness\", \"ADHD\", \"AD\", \"OCD\", \"DD\", \"BPD\", \"ODD\", \"CD\",\n",
    "                       \"PTSD\", \"PSYPATHO\", \"Internalization\", \"Externalization\", \"Stress\",\n",
    "                       \"PictureVocab\", \"Flanker\", \"ListSorting\", \"CardSort\",\n",
    "                       \"PatternComparison\", \"PictureSequence\", \"OralReading\",\n",
    "                       \"LMT\", \"RAVLT\", \"WISCMatrix\"]]\n",
    "\n",
    "# Assert the number of subjects retained is the same as before.\n",
    "assert abcd_data.shape[0] == psy_behav.shape[0], \"Number of subjects do not match.\"\n",
    "\n",
    "# Saving the final dataframe.\n",
    "abcd_data.to_excel(f'{output_dir}/abcd_data.xlsx', index=True, header=True)\n",
    "\n",
    "# This next line is commented out since data is protected by a data use agreement.\n",
    "# abcd_data.head() # Please inspect head of the dataframe to validate correct merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fetching relevant data for the Boston Adolescent Neuroimaging of Depression and Anxiety (BANDA) Study**\n",
    "\n",
    "Subsequent cells will load up data from the BANDA Data Release 1.1 and keep only relevant variables for the present analysis. Final table will be outputted in `output_dir`.\n",
    "\n",
    "Since the stress problems score is not precomputed within this study, we will manually compute it. Since the score calculations are proprietary, we derived the equation from the [ASEBA report](https://aseba.org/wp-content/uploads/cbclprofile.pdf). \n",
    "\n",
    "**Please note that this dataset is available through a data use agreement, for more information, please visit the [NIMH Data Archive website](https://nda.nih.gov/) or the [BANDA website](https://www.humanconnectome.org/study/connectomes-related-anxiety-depression/document/banda-release-11)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stress_problems(x):\n",
    "    \"\"\" \n",
    "    Function to compute the stress problems score.\n",
    "    \"\"\"\n",
    "    return x.cbcl3 + x.cbcl8 + x.cbcl9 + x.cbcl11 + x.cbcl31 + x.cbcl34 + x.cbcl45 +\\\n",
    "                  x.cbcl47 + x.cbcl50 + x.cbcl52 + x.cbcl69 + x.cbcl87 + x.cbcl103 + x.cbcl111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NIH toolbox.\n",
    "banda_dccs = load_df_in_any_format(f'{banda_dir}/dccs01.xlsx')\n",
    "banda_flanker = load_df_in_any_format(f'{banda_dir}/flanker01.xlsx')\n",
    "banda_lswm = load_df_in_any_format(f'{banda_dir}/lswmt01.xlsx')\n",
    "banda_orrt = load_df_in_any_format(f'{banda_dir}/orrt01.xlsx')\n",
    "banda_pcps = load_df_in_any_format(f'{banda_dir}/pcps01.xlsx')\n",
    "banda_pwmt = load_df_in_any_format(f'{banda_dir}/pwmt01.xlsx')\n",
    "banda_pmat = load_df_in_any_format(f'{banda_dir}/pmat01.xlsx')\n",
    "banda_wasi = load_df_in_any_format(f'{banda_dir}/wasi201.xlsx')\n",
    "banda_wasi = banda_wasi.loc[banda_wasi.respondent == 'Child']\n",
    "banda_cbcl = load_df_in_any_format(f'{banda_dir}/cbcl01.xlsx')\n",
    "banda_cbcl = banda_cbcl.loc[banda_cbcl.visit == 'T1']\n",
    "banda_hand = load_df_in_any_format(f'{banda_dir}/chaphand01.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables selection.\n",
    "banda_dccs = banda_dccs[['subjectkey', 'interview_age', 'nih_dccs_unadjusted']]\n",
    "banda_dccs.columns = ['subjectkey', 'Age', 'DCCS']\n",
    "banda_flanker = banda_flanker[['subjectkey', 'nih_flanker_unadjusted']]\n",
    "banda_flanker.columns = ['subjectkey', 'Flanker']\n",
    "banda_lswm = banda_lswm[['subjectkey', 'uss']]\n",
    "banda_lswm.columns = ['subjectkey', 'ListSorting']\n",
    "banda_orrt = banda_orrt[['subjectkey', 'read_uss']]\n",
    "banda_orrt.columns = ['subjectkey', 'OralReading']\n",
    "banda_pcps = banda_pcps[['subjectkey', 'nih_patterncomp_unadjusted']]\n",
    "banda_pcps.columns = ['subjectkey', 'PatternComparison']\n",
    "banda_pwmt = banda_pwmt[['subjectkey', 'cpw_cr']]\n",
    "banda_pwmt.columns = ['subjectkey', 'PennWM']\n",
    "banda_pmat = banda_pmat[['subjectkey', 'pmat24_a_cr']]\n",
    "banda_pmat.columns = ['subjectkey', 'PennMatrix']\n",
    "banda_wasi = banda_wasi[['subjectkey', 'vocab_totalrawscore']]\n",
    "banda_wasi.columns = ['subjectkey', 'WASIVocabulary']\n",
    "\n",
    "for df in [banda_dccs, banda_flanker, banda_lswm, banda_orrt, banda_pcps, banda_pwmt, banda_pmat]:\n",
    "    df.drop(0, axis=0, inplace=True)\n",
    "\n",
    "# Compute the cbcl stress problems score.\n",
    "for i in [3, 8, 9, 11, 31, 34, 45, 47, 50, 52, 69, 87, 103, 111]:\n",
    "    banda_cbcl.loc[:, f'cbcl{i}'] = banda_cbcl[f'cbcl{i}'].replace([999, 77, 88], 0)\n",
    "banda_cbcl.loc[:, 'cbcl_stress_raw'] = banda_cbcl.apply(compute_stress_problems, axis=1)\n",
    "\n",
    "banda_cbcl_vars = [\n",
    "    'subjectkey',\n",
    "    'cbcl_internal_raw',\n",
    "    'cbcl_external_raw',\n",
    "    'cbcl_stress_raw'\n",
    "]\n",
    "banda_cbcl = banda_cbcl[banda_cbcl_vars]\n",
    "banda_cbcl.columns = [\n",
    "    'subjectkey',\n",
    "    'Internalization',\n",
    "    'Externalization',\n",
    "    'Stress'\n",
    "]\n",
    "banda_cbcl = banda_cbcl.astype({'Internalization': 'float', 'Externalization': 'float', 'Stress': 'float'})\n",
    "\n",
    "# Scaling the data.\n",
    "banda_cbcl.loc[:, 'Internalization'] = StandardScaler().fit_transform(banda_cbcl[['Internalization']])\n",
    "banda_cbcl.loc[:, 'Externalization'] = StandardScaler().fit_transform(banda_cbcl[['Externalization']])\n",
    "banda_cbcl.loc[:, 'Stress'] = StandardScaler().fit_transform(banda_cbcl[['Stress']])\n",
    "banda_dccs.loc[:, 'DCCS'] = StandardScaler().fit_transform(banda_dccs[['DCCS']])\n",
    "banda_flanker.loc[:, 'Flanker'] = StandardScaler().fit_transform(banda_flanker[['Flanker']])\n",
    "banda_lswm.loc[:, 'ListSorting'] = StandardScaler().fit_transform(banda_lswm[['ListSorting']])\n",
    "banda_orrt.loc[:, 'OralReading'] = StandardScaler().fit_transform(banda_orrt[['OralReading']])\n",
    "banda_pcps.loc[:, 'PatternComparison'] = StandardScaler().fit_transform(banda_pcps[['PatternComparison']])\n",
    "banda_pwmt.loc[:, 'PennWM'] = StandardScaler().fit_transform(banda_pwmt[['PennWM']])\n",
    "banda_pmat.loc[:, 'PennMatrix'] = StandardScaler().fit_transform(banda_pmat[['PennMatrix']])\n",
    "banda_wasi.loc[:, 'WASIVocabulary'] = StandardScaler().fit_transform(banda_wasi[['WASIVocabulary']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching diagnoses data.\n",
    "!python \"{repository_path}/scripts/generate_dx_BANDA.py\" --in-root-folder \"{banda_dir}\" \\\n",
    "    --output \"{output_dir}/banda_dx_labels.xlsx\"\n",
    "\n",
    "# Importing back the diagnosis labels.\n",
    "banda_dx = load_df_in_any_format(f'{output_dir}/banda_dx_labels.xlsx')\n",
    "\n",
    "# Add a global psychopathology score (1 = at least one diagnosis, 0 = no diagnosis).\n",
    "banda_dx.loc[:, 'PSYPATHO'] = banda_dx.iloc[:, 1:].sum(axis=1).apply(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch demographics data.\n",
    "banda_demo = load_df_in_any_format('/Volumes/T7/CCPM/BANDA/BANDARelease1.1/demographics02.xlsx')\n",
    "banda_demo = banda_demo[banda_demo.visit == 'T1']\n",
    "banda_demo = banda_demo[['subjectkey', \"sex\", 'race', 'ethnicity', 'demo_parent_educ', 'demo_other_parent_educ']]\n",
    "banda_demo.loc[:, 'race_ethnicity'] = np.where(banda_demo['ethnicity'] == 'Hispanic or Latino',\n",
    "                                               banda_demo['ethnicity'],\n",
    "                                               np.where(banda_demo['race'] == 'More than one race',\n",
    "                                                        'Other',\n",
    "                                                        np.where(banda_demo['race'] == 'Unknown or not reported',\n",
    "                                                                 'Other',\n",
    "                                                                 banda_demo['race'])))\n",
    "banda_demo.loc[:, 'educ_level'] = banda_demo[['demo_parent_educ', 'demo_other_parent_educ']].values.max(1)\n",
    "\n",
    "# Transfer textual ethnicity to numerical. \n",
    "def ethnicity_coding(x):\n",
    "    if x.race_ethnicity == 'White':\n",
    "        return 1\n",
    "    elif x.race_ethnicity == \"Asian\":\n",
    "        return 4\n",
    "    elif x.race_ethnicity == \"Hispanic or Latino\":\n",
    "        return 3\n",
    "    elif x.race_ethnicity == \"Black or African American\":\n",
    "        return 2\n",
    "    elif x.race_ethnicity == \"Other\":\n",
    "        return 5\n",
    "    else:\n",
    "        ValueError(\"Invalid value.\")\n",
    "\n",
    "banda_demo.loc[:, 'race_ethnicity'] = banda_demo.apply(ethnicity_coding, axis=1)\n",
    "\n",
    "# Transfer textual sex variable to numerical. 1 = Male, 2 = Female.\n",
    "def sex_coding(x):\n",
    "    if x.sex == 'M':\n",
    "        return 1\n",
    "    elif x.sex == 'F':\n",
    "        return 2\n",
    "    else:\n",
    "        ValueError(\"Invalid value.\")\n",
    "\n",
    "banda_demo.loc[:, 'sex'] = banda_demo.apply(sex_coding, axis=1)\n",
    "\n",
    "# Small function to create education groups. (0-1 = 1: No high school,\n",
    "# 2 = 2: high school, 3-4 = 3: GED or equivalent, 5 = 4: some college,\n",
    "# 6 = 5: Bachelor's degree, 7-8 = 6: postgrad)\n",
    "def create_edu_groups(x):\n",
    "    if x < 2:\n",
    "        return 1\n",
    "    elif x == 2:\n",
    "        return 2\n",
    "    elif x in [3, 4]:\n",
    "        return 3\n",
    "    elif x == 5:\n",
    "        return 4\n",
    "    elif x == 6:\n",
    "        return 5\n",
    "    elif x > 6:\n",
    "        return 6\n",
    "\n",
    "banda_demo.insert(banda_demo.shape[1], 'edu_groups', banda_demo['educ_level'].apply(create_edu_groups))\n",
    "\n",
    "# Create handedness score. (1 = left, 2 = right, 3 = ambidextrous)\n",
    "def compute_handedness(x):\n",
    "    val = x.iloc[8:22].mode()[0]\n",
    "    if val == 0:\n",
    "        return 1\n",
    "    elif val == 1:\n",
    "        return 3\n",
    "    elif val == 2:\n",
    "        return 2\n",
    "    else:\n",
    "        ValueError(\"Handedness not found.\")\n",
    "\n",
    "banda_hand.loc[:, 'Handedness'] = banda_hand.apply(compute_handedness, axis=1)\n",
    "banda_hand = banda_hand[['subjectkey', 'Handedness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects retained for the analysis: 197\n"
     ]
    }
   ],
   "source": [
    "# Merging behavioral and psychometric data first, to avoid unnecessary loss of subjects.\n",
    "# After that, merging with demographics.\n",
    "ncogn = merge_dataframes({\"cbcl\":banda_cbcl, \"dccs\": banda_dccs, \"flanker\": banda_flanker,\n",
    "                            \"lswm\": banda_lswm, \"orrt\": banda_orrt,\n",
    "                            \"pcps\": banda_pcps, \"pwmt\": banda_pwmt,\n",
    "                            \"pmat\": banda_pmat, \"wasi\": banda_wasi}, index=\"subjectkey\")\n",
    "ncogn.dropna(inplace=True, axis=0)\n",
    "ncogn.reset_index(drop=False, inplace=True)\n",
    "print(\"Number of subjects retained for the analysis: {}\".format(ncogn.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with demographics.\n",
    "banda_data = merge_dataframes({\"demo\": banda_demo, \"hand\": banda_hand, \"dx\": banda_dx, \"ncogn\": ncogn},\n",
    "                               index=\"subjectkey\")\n",
    "# Dropping rows with NA in the last 6 columns which corresponds to the behavioral and psychometric data.\n",
    "banda_data.dropna(inplace=True, axis=0, subset=banda_data.columns[-6:], how=\"all\")\n",
    "\n",
    "# Dropping two subjects due to missing handedness data.\n",
    "banda_data.dropna(subset=['Handedness'], inplace=True)\n",
    "\n",
    "# Reordering the columns.\n",
    "banda_data = banda_data[['sex', 'Age', 'race_ethnicity', 'demo_parent_educ',\n",
    "                         'demo_other_parent_educ', 'educ_level', 'edu_groups',\n",
    "                         'Handedness', 'ADHD', 'AD', 'CD', 'DD', 'ODD', 'OCD', \"PSYPATHO\",\n",
    "                         'Internalization', 'Externalization', 'Stress', 'DCCS',\n",
    "                         'Flanker', 'ListSorting', 'OralReading', 'PatternComparison',\n",
    "                         'PennWM', 'PennMatrix', 'WASIVocabulary']]\n",
    "banda_data.columns = ['Sex', 'AgeMonths', 'Ethnicity', 'Parent_ed1',\n",
    "                      'Parent_ed2', 'high_edu', 'edu_groups', 'Handedness', 'ADHD',\n",
    "                        'AD', 'CD', 'DD', 'ODD', 'OCD', \"PSYPATHO\", 'Internalization', 'Externalization',\n",
    "                        'Stress', 'DCCS', 'Flanker', 'ListSorting', 'OralReading',\n",
    "                        'PatternComparison', 'PennWM', 'PennMatrix', 'WASIVocabulary']\n",
    "\n",
    "# Assert the number of subjects retained is the same as before (minus the two dropped).\n",
    "assert banda_data.shape[0] == ncogn.shape[0] - 2, \"Number of subjects do not match.\"\n",
    "\n",
    "# Saving the final dataframe.\n",
    "banda_data.to_excel(f'{output_dir}/banda_data.xlsx', index=True, header=True)\n",
    "\n",
    "# This next line is commented out since data is protected by a data use agreement.\n",
    "# banda_data.head() # Please inspect head of the dataframe to validate correct merging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fetching data from the GESTE Study**\n",
    "\n",
    "Subsequent cells will fetch data from the GESTE Study and keep only relevant variables for the present analysis. Final dataframe will be outputted in `output_dir`. \n",
    "\n",
    "**Please note that this dataset is not publicly available. To gain access to this data, please contact Dr. Larissa Takser PhD (larissa.takser@usherbrooke.ca)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data. \n",
    "geste_neuro = load_df_in_any_format(f'{geste_base_dir}/Neurocognitive/neurocognitive_data.xlsx')\n",
    "geste_demo = load_df_in_any_format(f'{geste_base_dir}/PopInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching neurocognitive data.\n",
    "neuro_vars = [\n",
    "    'record_id',\n",
    "    'basc3_epi_t',\n",
    "    'basc3_ipi_t',\n",
    "    'wisc5_bl_ss',\n",
    "    'wisc5_si_ss',\n",
    "    'wisc5_ma_ss',\n",
    "    'wisc5_sc_ss',\n",
    "    'wisc5_cd_ss',\n",
    "    'wisc5_vc_ss',\n",
    "    'wisc5_ba_ss',\n",
    "]\n",
    "neuro_df = geste_neuro[neuro_vars]\n",
    "neuro_df.columns = [\n",
    "    'subjectkey',\n",
    "    'Externalizing',\n",
    "    'Internalizing',\n",
    "    'Block',\n",
    "    'Similarities',\n",
    "    'MatrixReasoning',\n",
    "    'DigitSpan',\n",
    "    'Code',\n",
    "    'Vocabulary',\n",
    "    'Balance',\n",
    "]\n",
    "# Set to correct dtypes.\n",
    "neuro_df = neuro_df.astype({'Block': 'float', 'Similarities': 'float', 'MatrixReasoning': 'float',\n",
    "                 'DigitSpan': 'float', 'Code': 'float', 'Vocabulary': 'float', 'Balance': 'float'},\n",
    "                 copy=True)\n",
    "\n",
    "neuro_df.loc[:, 'Externalizing'] = StandardScaler().fit_transform(neuro_df[['Externalizing']])\n",
    "neuro_df.loc[:, 'Internalizing'] = StandardScaler().fit_transform(neuro_df[['Internalizing']])\n",
    "neuro_df.loc[:, 'Block'] = StandardScaler().fit_transform(neuro_df[['Block']])\n",
    "neuro_df.loc[:, 'Similarities'] = StandardScaler().fit_transform(neuro_df[['Similarities']])\n",
    "neuro_df.loc[:, 'MatrixReasoning'] = StandardScaler().fit_transform(neuro_df[['MatrixReasoning']])\n",
    "neuro_df.loc[:, 'DigitSpan'] = StandardScaler().fit_transform(neuro_df[['DigitSpan']])\n",
    "neuro_df.loc[:, 'Code'] = StandardScaler().fit_transform(neuro_df[['Code']])\n",
    "neuro_df.loc[:, 'Vocabulary'] = StandardScaler().fit_transform(neuro_df[['Vocabulary']])\n",
    "neuro_df.loc[:, 'Balance'] = StandardScaler().fit_transform(neuro_df[['Balance']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/23/p0fh1nrd473dtfz3cx_4g0j00000gn/T/ipykernel_3023/67950795.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  psycho_patho.loc[:, 'PSYPATHO'] = psycho_patho.iloc[:, 1:].sum(axis=1).apply(lambda x: 1 if x > 0 else 0)\n"
     ]
    }
   ],
   "source": [
    "# Selecting population variables.\n",
    "psycho_patho = geste_demo[['record_id', 'tsa_ea6d8f', 'tdha']]\n",
    "psycho_patho.columns = ['subjectkey', 'ASD', 'ADHD']\n",
    "\n",
    "# Recoding diagnosis data, 1 = present, 0 = absent.\n",
    "def recode_diagnosis(x):\n",
    "    if x == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "psycho_patho.loc[:, 'ASD'] = psycho_patho['ASD'].apply(recode_diagnosis)\n",
    "psycho_patho.loc[:, 'ADHD'] = psycho_patho['ADHD'].apply(recode_diagnosis)\n",
    "\n",
    "# Add a global psychopathology score (1 = at least one diagnosis, 0 = no diagnosis).\n",
    "psycho_patho.loc[:, 'PSYPATHO'] = psycho_patho.iloc[:, 1:].sum(axis=1).apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "geste_demo = geste_demo[['record_id', 'sexe_bb', 'child_age_assmt_auto',\n",
    "                         'revenu_dc4c4c', 'origin_eth_enf', 'etudes', 'etudes2',\n",
    "                         'mainpegboard___1', 'mainpegboard___2']]\n",
    "geste_demo.columns = [\n",
    "    'subjectkey',\n",
    "    'Sex',\n",
    "    'Age',\n",
    "    'Income',\n",
    "    'Ethnicity',\n",
    "    'etudes',\n",
    "    'etudes2',\n",
    "    'lefthanded',\n",
    "    'righthanded'\n",
    "]\n",
    "\n",
    "# Setting sex variable to 1 = Male, 2 = Female. \n",
    "def sex_coding(x):\n",
    "    if x.Sex == 1:\n",
    "        return 1\n",
    "    elif x.Sex == 0:\n",
    "        return 2\n",
    "    else:\n",
    "        ValueError(\"Invalid value.\")\n",
    "\n",
    "geste_demo.loc[:, 'Sex'] = geste_demo.apply(sex_coding, axis=1)\n",
    "\n",
    "# Transfer age in years to months.\n",
    "geste_demo.loc[:, 'AgeMonths'] = np.round(geste_demo.Age * 12, 0)\n",
    "\n",
    "# Lumping handedness variables together.\n",
    "# 1 = Left handed, 2 = Right handed.\n",
    "def handedness(x):\n",
    "    if x.lefthanded == 1 and x.righthanded != 1:\n",
    "        return 1\n",
    "    elif x.lefthanded != 1 and x.righthanded == 1:\n",
    "        return 2\n",
    "    else:\n",
    "        ValueError(\"Both variables are not consistent.\")\n",
    "\n",
    "geste_demo.insert(geste_demo.shape[1], 'Handedness', geste_demo.apply(handedness, axis=1))\n",
    "\n",
    "# Converting CAD to USD dollars. (using the rate on april 22nd 2024.)\n",
    "geste_demo.loc[:, 'Income'] = geste_demo['Income'] * 0.73\n",
    "\n",
    "# Dummy function to create income groups. \n",
    "def income_groups(x):\n",
    "    if x < 50000:\n",
    "        return 1\n",
    "    elif 50000 <= x < 100000:\n",
    "        return 2\n",
    "    elif x >= 100000:\n",
    "        return 3\n",
    "\n",
    "geste_demo.insert(geste_demo.shape[1], 'Income_groups', geste_demo['Income'].apply(income_groups))\n",
    "\n",
    "# Dummy function to create ethnic groups.\n",
    "# 1 = White, 2 = Black, 3 = Hispanic, 4 = Asian, 5 = Other.\n",
    "def ethnic_groups_coding(x):\n",
    "    if x in [3, 9, 10]:\n",
    "        return 1\n",
    "    elif x in [8, 7, 6]:\n",
    "        return 4\n",
    "    elif x in [1, 2]:\n",
    "        return 2\n",
    "    elif x == 4:\n",
    "        return 3\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "geste_demo.insert(geste_demo.shape[1], 'ethnic_groups', geste_demo['Ethnicity'].apply(ethnic_groups_coding))\n",
    "\n",
    "# Taking highest education level completed.\n",
    "def education_coding(x):\n",
    "    if pd.isna(x.etudes) and pd.notna(x.etudes2):\n",
    "        return x.etudes2\n",
    "    elif pd.notna(x.etudes) and pd.isna(x.etudes2):\n",
    "        return x.etudes\n",
    "    elif pd.notna(x.etudes) and pd.notna(x.etudes2):\n",
    "        return max(x.etudes, x.etudes2)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "geste_demo.loc[:, 'edu_groups'] = geste_demo.apply(education_coding, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects retained for the analysis: 271\n"
     ]
    }
   ],
   "source": [
    "# Merging with neurocognitive and behavioral data.\n",
    "geste_inter = merge_dataframes({\"psycho\": psycho_patho, \"neuro\": neuro_df}, index=\"subjectkey\")\n",
    "geste_inter.dropna(inplace=True, axis=0)\n",
    "geste_inter.reset_index(drop=False, inplace=True)\n",
    "\n",
    "print(\"Number of subjects retained for the analysis: {}\".format(geste_inter.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging with demographics.\n",
    "geste_data = merge_dataframes({\"geste_inter\": geste_inter,\n",
    "                               \"demo\": geste_demo, }, index=\"subjectkey\")\n",
    "\n",
    "# Dropping rows with NA in the last 6 columns which corresponds to the behavioral and psychometric data.\n",
    "geste_data.dropna(inplace=True, axis=0, subset=geste_data.columns[-6:], how=\"all\")\n",
    "\n",
    "# Reordering columns.\n",
    "geste_data = geste_data[['Sex', 'AgeMonths', 'ethnic_groups', 'etudes', 'etudes2', 'edu_groups',\n",
    "                         'Income', 'Income_groups', 'Handedness',\n",
    "                         'ASD', 'ADHD', \"PSYPATHO\", 'Internalizing', 'Externalizing', 'Block',\n",
    "                         'Similarities', 'MatrixReasoning', 'DigitSpan', 'Code',\n",
    "                         'Vocabulary', 'Balance']]\n",
    "\n",
    "# Renaming the columns to match ABCD dataset.\n",
    "geste_data.columns = [\"Sex\", 'AgeMonths', 'Ethnicity', 'Parent_ed1', 'Parent_ed2', 'edu_groups',\n",
    "                      'Income', 'Income_groups', 'Handedness', 'ASD', 'ADHD', \"PSYPATHO\", 'Internalization',\n",
    "                      'Externalization', 'Block', 'Similarities', 'MatrixReasoning', 'DigitSpan',\n",
    "                      'Code', 'Vocabulary', 'Balance']\n",
    "\n",
    "# Assert the number of subjects retained is the same as before.\n",
    "assert geste_data.shape[0] == geste_inter.shape[0], \"Number of subjects do not match.\"\n",
    "\n",
    "# Saving the final dataframe.\n",
    "geste_data.to_excel(f'{output_dir}/geste_data.xlsx', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccpm-FPLdOtB--py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
