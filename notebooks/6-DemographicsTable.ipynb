{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creating a demographic table including each study stratified by sex.**\n",
    "\n",
    "Creating the classic demographic table, Table 1 in Gagnon et al., 2025. This section will pool data from\n",
    "the different studies and compute mean, std, % or count when appropriate. The output will be a\n",
    "roughly formatted excel table. Final formatting should be done by hand in excel/word but the raw values\n",
    "should stay the same.\n",
    "\n",
    "**The following variables (stratified by sex) will be incorporated in the final table:**\n",
    "\n",
    "1. N (%) \n",
    "1. Age, months (std)\n",
    "1. Race/Ethnicity, count (%)\n",
    "1. Highest parental education, count (%)\n",
    "1. Familial Income (USD$), count (%)\n",
    "1. Psychopathology, count (%)\n",
    "1. Cognitive and Behavioral scores, mean (std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from neurostatx.io.utils import load_df_in_any_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up relevant paths.\n",
    "repository_path = \"/Users/anthonygagnon/code/Article-s-Code/\" # CHANGE THIS\n",
    "abcd_base_path = \"/Volumes/T7/CCPM/ABCD/Release_5.1/abcd-data-release-5.1/\" # CHANGE THIS\n",
    "geste_base_dir = \"/Volumes/T7/CCPM/GESTE/\" # CHANGE THIS\n",
    "banda_dir = '/Volumes/T7/CCPM/BANDA/BANDARelease1.1/' # CHANGE THIS\n",
    "output_folder = \"/Volumes/T7/CCPM/RESULTS_JUNE_24/\" # CHANGE THIS\n",
    "data_dir = f\"{output_folder}/preprocessing/\"\n",
    "output_dir = f\"{output_folder}/demographicstable/\"\n",
    "\n",
    "# Create output directory if it does not exist.\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up ABCD data.\n",
    "abcd_data = load_df_in_any_format(f'{data_dir}/abcd_data_preprocessed.xlsx')\n",
    "\n",
    "# This next line is commented out since data is protected by a data use agreement.\n",
    "#abcd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethnicity demographics within the ABCD data.\n",
    "abcd_male = abcd_data[abcd_data.Sex == 1]\n",
    "abcd_female = abcd_data[abcd_data.Sex == 2]\n",
    "abcd_ethn_m = abcd_male.Ethnicity.value_counts()\n",
    "abcd_ethn_f = abcd_female.Ethnicity.value_counts()\n",
    "\n",
    "# Parental education demographics within the ABCD data.\n",
    "abcd_male_edu = abcd_male.edu_groups.value_counts()\n",
    "abcd_female_edu = abcd_female.edu_groups.value_counts()\n",
    "\n",
    "# Income demographics within the ABCD data.\n",
    "abcd_male_inc = abcd_male.income_groups.value_counts()\n",
    "abcd_female_inc = abcd_female.income_groups.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching the mean values and appending them to a list.\n",
    "male_desc = [\n",
    "    [abcd_male.count().iloc[0], np.round(abcd_male.count().iloc[0] * 100 / abcd_data.shape[0], 2)],\n",
    "    [np.round(abcd_male.AgeMonths.mean(), 2), np.round(abcd_male.AgeMonths.std(), 2)],\n",
    "    [abcd_ethn_m.loc[1], np.round(abcd_ethn_m.loc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_ethn_m.loc[2], np.round(abcd_ethn_m.loc[2] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_ethn_m.loc[3], np.round(abcd_ethn_m.loc[3] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_ethn_m.loc[4], np.round(abcd_ethn_m.loc[4] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_ethn_m.loc[5], np.round(abcd_ethn_m.loc[5] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male_edu.loc[1], np.round(abcd_male_edu.loc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male_edu.loc[2], np.round(abcd_male_edu.loc[2] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male_edu.loc[3], np.round(abcd_male_edu.loc[3] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male_edu.loc[4], np.round(abcd_male_edu.loc[4] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male_edu.loc[5], np.round(abcd_male_edu.loc[5] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male_inc.loc[1], np.round(abcd_male_inc.loc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male_inc.loc[2], np.round(abcd_male_inc.loc[2] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male_inc.loc[3], np.round(abcd_male_inc.loc[3] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male.AD.value_counts().iloc[1], np.round(abcd_male.AD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male.ADHD.value_counts().iloc[1], np.round(abcd_male.ADHD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male.CD.value_counts().iloc[1], np.round(abcd_male.CD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male.DD.value_counts().iloc[1], np.round(abcd_male.DD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male.OCD.value_counts().iloc[1], np.round(abcd_male.OCD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_male.ODD.value_counts().iloc[1], np.round(abcd_male.ODD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [np.round(abcd_male.Internalization.mean(), 2), np.round(abcd_male.Internalization.std(), 2)],\n",
    "    [np.round(abcd_male.Externalization.mean(), 2), np.round(abcd_male.Externalization.std(), 2)],\n",
    "    [np.round(abcd_male.Stress.mean(), 2), np.round(abcd_male.Stress.std(), 2)],\n",
    "    [np.round(abcd_male.VA.mean(), 2), np.round(abcd_male.VA.std(), 2)],\n",
    "    [np.round(abcd_male.EFPS.mean(), 2), np.round(abcd_male.EFPS.std(), 2)],\n",
    "    [np.round(abcd_male.MEM.mean(), 2), np.round(abcd_male.MEM.std(), 2)]\n",
    "]\n",
    "\n",
    "female_desc = [\n",
    "    [abcd_female.count().iloc[0], np.round(abcd_female.count().iloc[0] * 100 / abcd_data.shape[0], 2)],\n",
    "    [np.round(abcd_female.AgeMonths.mean(), 2), np.round(abcd_female.AgeMonths.std(), 2)],\n",
    "    [abcd_ethn_f.loc[1], np.round(abcd_ethn_f.loc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_ethn_f.loc[2], np.round(abcd_ethn_f.loc[2] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_ethn_f.loc[3], np.round(abcd_ethn_f.loc[3] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_ethn_f.loc[4], np.round(abcd_ethn_f.loc[4] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_ethn_f.loc[5], np.round(abcd_ethn_f.loc[5] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female_edu.loc[1], np.round(abcd_female_edu.loc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female_edu.loc[2], np.round(abcd_female_edu.loc[2] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female_edu.loc[3], np.round(abcd_female_edu.loc[3] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female_edu.loc[4], np.round(abcd_female_edu.loc[4] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female_edu.loc[5], np.round(abcd_female_edu.loc[5] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female_inc.loc[1], np.round(abcd_female_inc.loc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female_inc.loc[2], np.round(abcd_female_inc.loc[2] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female_inc.loc[3], np.round(abcd_female_inc.loc[3] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female.AD.value_counts().iloc[1], np.round(abcd_female.AD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female.ADHD.value_counts().iloc[1], np.round(abcd_female.ADHD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female.CD.value_counts().iloc[1], np.round(abcd_female.CD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female.DD.value_counts().iloc[1], np.round(abcd_female.DD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female.OCD.value_counts().iloc[1], np.round(abcd_female.OCD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [abcd_female.ODD.value_counts().iloc[1], np.round(abcd_female.ODD.value_counts().iloc[1] * 100 / abcd_data.shape[0], 2)],\n",
    "    [np.round(abcd_female.Internalization.mean(), 2), np.round(abcd_female.Internalization.std(), 2)],\n",
    "    [np.round(abcd_female.Externalization.mean(), 2), np.round(abcd_female.Externalization.std(), 2)],\n",
    "    [np.round(abcd_female.Stress.mean(), 2), np.round(abcd_female.Stress.std(), 2)],\n",
    "    [np.round(abcd_female.VA.mean(), 2), np.round(abcd_female.VA.std(), 2)],\n",
    "    [np.round(abcd_female.EFPS.mean(), 2), np.round(abcd_female.EFPS.std(), 2)],\n",
    "    [np.round(abcd_female.MEM.mean(), 2), np.round(abcd_female.MEM.std(), 2)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up BANDA data.\n",
    "banda_data = load_df_in_any_format(f'{data_dir}/banda_data_preprocessed.xlsx')\n",
    "\n",
    "# This next line is commented out since data is protected by a data use agreement.\n",
    "#banda_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into female and male, then compute statistics.\n",
    "banda_male = banda_data[banda_data.Sex == 1]\n",
    "banda_female = banda_data[banda_data.Sex == 2]\n",
    "\n",
    "# Compute various stats.\n",
    "banda_male_desc = [\n",
    "    [banda_male.count().iloc[0], np.round(banda_male.count().iloc[0] * 100 / banda_data.shape[0], 2)],\n",
    "    [np.round(banda_male.AgeMonths.mean(), 2), np.round(banda_male.AgeMonths.std(), 2)],\n",
    "    [banda_male.Ethnicity.value_counts().loc[1], np.round(banda_male.Ethnicity.value_counts().loc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_male.Ethnicity.value_counts().loc[2], np.round(banda_male.Ethnicity.value_counts().loc[2] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_male.Ethnicity.value_counts().loc[3], np.round(banda_male.Ethnicity.value_counts().loc[3] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_male.Ethnicity.value_counts().loc[4], np.round(banda_male.Ethnicity.value_counts().loc[4] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_male.Ethnicity.value_counts().loc[5], np.round(banda_male.Ethnicity.value_counts().loc[5] * 100 / banda_data.shape[0], 2)],\n",
    "    '-',\n",
    "    '-',\n",
    "    [banda_male.edu_groups.value_counts().loc[4], np.round(banda_male.edu_groups.value_counts().loc[4] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_male.edu_groups.value_counts().loc[5], np.round(banda_male.edu_groups.value_counts().loc[5] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_male.edu_groups.value_counts().loc[6], np.round(banda_male.edu_groups.value_counts().loc[6] * 100 / banda_data.shape[0], 2)],\n",
    "    '-',\n",
    "    '-',\n",
    "    '-',\n",
    "    [banda_male.AD.value_counts().iloc[1], np.round(banda_male.AD.value_counts().iloc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_male.ADHD.value_counts().iloc[1], np.round(banda_male.ADHD.value_counts().iloc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    '-',\n",
    "    [banda_male.DD.value_counts().iloc[1], np.round(banda_male.DD.value_counts().iloc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_male.OCD.value_counts().iloc[1], np.round(banda_male.OCD.value_counts().iloc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_male.ODD.value_counts().iloc[1], np.round(banda_male.ODD.value_counts().iloc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    [np.round(banda_male.Internalization.mean(), 2), np.round(banda_male.Internalization.std(), 2)],\n",
    "    [np.round(banda_male.Externalization.mean(), 2), np.round(banda_male.Externalization.std(), 2)],\n",
    "    [np.round(banda_male.Stress.mean(), 2), np.round(banda_male.Stress.std(), 2)],\n",
    "    [np.round(banda_male.VA.mean(), 2), np.round(banda_male.VA.std(), 2)],\n",
    "    [np.round(banda_male.EFPS.mean(), 2), np.round(banda_male.EFPS.std(), 2)],\n",
    "    [np.round(banda_male.MEM.mean(), 2), np.round(banda_male.MEM.std(), 2)]\n",
    "]\n",
    "banda_female_desc = [\n",
    "    [banda_female.count().iloc[0], np.round(banda_female.count().iloc[0] * 100 / banda_data.shape[0], 2)],\n",
    "    [np.round(banda_female.AgeMonths.mean(), 2), np.round(banda_female.AgeMonths.std(), 2)],\n",
    "    [banda_female.Ethnicity.value_counts().loc[1], np.round(banda_female.Ethnicity.value_counts().loc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_female.Ethnicity.value_counts().loc[2], np.round(banda_female.Ethnicity.value_counts().loc[2] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_female.Ethnicity.value_counts().loc[3], np.round(banda_female.Ethnicity.value_counts().loc[3] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_female.Ethnicity.value_counts().loc[4], np.round(banda_female.Ethnicity.value_counts().loc[4] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_female.Ethnicity.value_counts().loc[5], np.round(banda_female.Ethnicity.value_counts().loc[5] * 100 / banda_data.shape[0], 2)],\n",
    "    '-',\n",
    "    '-',\n",
    "    [banda_female.edu_groups.value_counts().loc[4], np.round(banda_female.edu_groups.value_counts().loc[4] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_female.edu_groups.value_counts().loc[5], np.round(banda_female.edu_groups.value_counts().loc[5] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_female.edu_groups.value_counts().loc[6], np.round(banda_female.edu_groups.value_counts().loc[6] * 100 / banda_data.shape[0], 2)],\n",
    "    '-',\n",
    "    '-',\n",
    "    '-',\n",
    "    [banda_female.AD.value_counts().iloc[1], np.round(banda_female.AD.value_counts().iloc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_female.ADHD.value_counts().iloc[1], np.round(banda_female.ADHD.value_counts().iloc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    '-',\n",
    "    [banda_female.DD.value_counts().iloc[1], np.round(banda_female.DD.value_counts().iloc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_female.OCD.value_counts().iloc[1], np.round(banda_female.OCD.value_counts().iloc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    [banda_female.ODD.value_counts().iloc[1], np.round(banda_female.ODD.value_counts().iloc[1] * 100 / banda_data.shape[0], 2)],\n",
    "    [np.round(banda_female.Internalization.mean(), 2), np.round(banda_female.Internalization.std(), 2)],\n",
    "    [np.round(banda_female.Externalization.mean(), 2), np.round(banda_female.Externalization.std(), 2)],\n",
    "    [np.round(banda_female.Stress.mean(), 2), np.round(banda_female.Stress.std(), 2)],\n",
    "    [np.round(banda_female.VA.mean(), 2), np.round(banda_female.VA.std(), 2)],\n",
    "    [np.round(banda_female.EFPS.mean(), 2), np.round(banda_female.EFPS.std(), 2)],\n",
    "    [np.round(banda_female.MEM.mean(), 2), np.round(banda_female.MEM.std(), 2)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up GESTE data.\n",
    "geste_data = load_df_in_any_format(f'{data_dir}/geste_data_preprocessed.xlsx')\n",
    "\n",
    "# This next line is commented out since data is protected by a data use agreement.\n",
    "#geste_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "geste_male = geste_data[geste_data.Sex == 1]\n",
    "geste_female = geste_data[geste_data.Sex == 2]\n",
    "\n",
    "geste_male_desc = [\n",
    "    [geste_male.count().iloc[0], np.round(geste_male.count().iloc[0] * 100 / geste_data.shape[0], 2)],\n",
    "    [np.round(geste_male.AgeMonths.mean(), 2), np.round(geste_male.AgeMonths.std(), 2)],\n",
    "    [geste_male.Ethnicity.value_counts().loc[1], np.round(geste_male.Ethnicity.value_counts().loc[1] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_male.Ethnicity.value_counts().loc[2], np.round(geste_male.Ethnicity.value_counts().loc[2] * 100 / geste_data.shape[0], 2)],\n",
    "    '-',\n",
    "    '-',\n",
    "    [geste_male.Ethnicity.value_counts().loc[5], np.round(geste_male.Ethnicity.value_counts().loc[5] * 100 / geste_data.shape[0], 2)],\n",
    "    '-',\n",
    "    [geste_male.edu_groups.value_counts().loc[2], np.round(geste_male.edu_groups.value_counts().loc[2] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_male.edu_groups.value_counts().loc[3] + geste_male.edu_groups.value_counts().loc[5], np.round((geste_male.edu_groups.value_counts().loc[3] + geste_male.edu_groups.value_counts().loc[5]) * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_male.edu_groups.value_counts().loc[4], np.round(geste_male.edu_groups.value_counts().loc[4] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_male.edu_groups.value_counts().loc[6], np.round(geste_male.edu_groups.value_counts().loc[6] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_male.Income_groups.value_counts().loc[1], np.round(geste_male.Income_groups.value_counts().loc[1] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_male.Income_groups.value_counts().loc[2], np.round(geste_male.Income_groups.value_counts().loc[2] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_male.Income_groups.value_counts().loc[3], np.round(geste_male.Income_groups.value_counts().loc[3] * 100 / geste_data.shape[0], 2)],\n",
    "    '-',\n",
    "    [geste_male.ADHD.value_counts().iloc[1], np.round(geste_male.ADHD.value_counts().iloc[1] * 100 / geste_data.shape[0], 2)],\n",
    "    '-',\n",
    "    '-',\n",
    "    '-',\n",
    "    '-',\n",
    "    [np.round(geste_male.Internalization.mean(), 2), np.round(geste_male.Internalization.std(), 2)],\n",
    "    [np.round(geste_male.Externalization.mean(), 2), np.round(geste_male.Externalization.std(), 2)],\n",
    "    [np.round(geste_male.Stress.mean(), 2), np.round(geste_male.Stress.std(), 2)],\n",
    "    [np.round(geste_male.VA.mean(), 2), np.round(geste_male.VA.std(), 2)],\n",
    "    [np.round(geste_male.EFPS.mean(), 2), np.round(geste_male.EFPS.std(), 2)],\n",
    "    [np.round(geste_male.MEM.mean(), 2), np.round(geste_male.MEM.std(), 2)]\n",
    "]\n",
    "\n",
    "geste_female_desc = [\n",
    "    [geste_female.count().iloc[0], np.round(geste_female.count().iloc[0] * 100 / geste_data.shape[0], 2)],\n",
    "    [np.round(geste_female.AgeMonths.mean(), 2), np.round(geste_female.AgeMonths.std(), 2)],\n",
    "    [geste_female.Ethnicity.value_counts().loc[1], np.round(geste_female.Ethnicity.value_counts().loc[1] * 100 / geste_data.shape[0], 2)],\n",
    "    '-',\n",
    "    [geste_female.Ethnicity.value_counts().loc[3], np.round(geste_female.Ethnicity.value_counts().loc[3] * 100 / geste_data.shape[0], 2)],\n",
    "    '-',\n",
    "    [geste_female.Ethnicity.value_counts().loc[5], np.round(geste_female.Ethnicity.value_counts().loc[5] * 100 / geste_data.shape[0], 2)],\n",
    "    '-',\n",
    "    [geste_female.edu_groups.value_counts().loc[2], np.round(geste_female.edu_groups.value_counts().loc[2] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_female.edu_groups.value_counts().loc[3] + geste_female.edu_groups.value_counts().loc[5], np.round((geste_female.edu_groups.value_counts().loc[3] + geste_female.edu_groups.value_counts().loc[5]) * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_female.edu_groups.value_counts().loc[4], np.round(geste_female.edu_groups.value_counts().loc[4] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_female.edu_groups.value_counts().loc[6], np.round(geste_female.edu_groups.value_counts().loc[6] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_female.Income_groups.value_counts().loc[1], np.round(geste_female.Income_groups.value_counts().loc[1] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_female.Income_groups.value_counts().loc[2], np.round(geste_female.Income_groups.value_counts().loc[2] * 100 / geste_data.shape[0], 2)],\n",
    "    [geste_female.Income_groups.value_counts().loc[3], np.round(geste_female.Income_groups.value_counts().loc[3] * 100 / geste_data.shape[0], 2)],\n",
    "    '-',\n",
    "    [geste_female.ADHD.value_counts().iloc[1], np.round(geste_female.ADHD.value_counts().iloc[1] * 100 / geste_data.shape[0], 2)],\n",
    "    '-',\n",
    "    '-',\n",
    "    '-',\n",
    "    '-',\n",
    "    [np.round(geste_female.Internalization.mean(), 2), np.round(geste_female.Internalization.std(), 2)],\n",
    "    [np.round(geste_female.Externalization.mean(), 2), np.round(geste_female.Externalization.std(), 2)],\n",
    "    [np.round(geste_female.Stress.mean(), 2), np.round(geste_female.Stress.std(), 2)],\n",
    "    [np.round(geste_female.VA.mean(), 2), np.round(geste_female.VA.std(), 2)],\n",
    "    [np.round(geste_female.EFPS.mean(), 2), np.round(geste_female.EFPS.std(), 2)],\n",
    "    [np.round(geste_female.MEM.mean(), 2), np.round(geste_female.MEM.std(), 2)]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging everything together into a single demographics table.\n",
    "demo_table = pd.DataFrame({\n",
    "    \"abcd_male\": male_desc,\n",
    "    \"abcd_female\": female_desc,\n",
    "    \"banda_male\": banda_male_desc,\n",
    "    \"banda_female\": banda_female_desc,\n",
    "    \"geste_male\": geste_male_desc,\n",
    "    \"geste_female\": geste_female_desc\n",
    "})\n",
    "demo_table.index = [\n",
    "    \"N\", \"Age (months)\", \"White\", \"Black or African American\", \"Hispanic or Latino\", \"Asian\", \"Other\",\n",
    "    \"No Highschool\", \"Highschool, GED, or equivalent\", \"Some college\", \"Bachelor Degree\", \"Postgraduate Degree\",\n",
    "    \"Income < 50 000$USD\", \"Income 50 000-100 000$USD\", \"Income > 100 000$USD\", \n",
    "    \"AD (%)\", \"ADHD (%)\", \"CD (%)\", \"DD (%)\", \"OCD (%)\", \"ODD (%)\",\n",
    "    \"Internalization (mean)\", \"Externalization (mean)\", \"Stress (mean)\", \"VA (mean)\", \"EFPS (mean)\", \"MEM (mean)\"\n",
    "]\n",
    "demo_table.to_excel(f'{output_dir}/demo_table.xlsx', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
